# -*- coding: utf-8 -*-
"""Fraud detection implementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s4TpxNQPp54LR_idhCT9ObsjXr-BDpri

GOD **CR**cf*mv* 2025Feb16
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

def load_processed_data():
    """
    Load the processed data saved from the EDA notebook
    """
    try:
        df = pd.read_parquet('/content/drive/MyDrive/SP3-Caterpillar/processed_transactions.parquet')
        print("Processed data loaded successfully")
        return df
    except FileNotFoundError:
        print("Error: Processed data file not found. Run the EDA notebook first.")
        return None

def create_feature_engineering(df):
    """
    Create features for fraud detection
    """
    # Time-based features
    df['hour'] = df['date'].dt.hour
    df['day_of_week'] = df['date'].dt.dayofweek
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

    # Amount-based features
    df['amount_mean'] = df.groupby('account_id')['amount'].transform('mean')
    df['amount_std'] = df.groupby('account_id')['amount'].transform('std')
    df['amount_zscore'] = (df['amount'] - df['amount_mean']) / df['amount_std']

    # Transaction velocity features
    df['date'] = pd.to_datetime(df['date'])  # Convert to datetime if not already
    df = df.sort_values(by=['account_id', 'date'])  # Sort by account_id and date

    # Set 'date' as index and group by 'account_id'
    df = df.set_index('date')
    df['trans_count_1d'] = df.groupby('account_id')['amount'].transform(
        lambda x: x.rolling('1D', min_periods=1).count()
    )
    df = df.reset_index()  # Reset index if needed

    # Balance-based features
    df['balance_change'] = df.groupby('account_id')['balance'].transform('diff')

    # Operation type patterns
    df['operation_count'] = df.groupby(['account_id', 'operation'])['operation'].transform('count')

    # Fill NaN values with 0
    df = df.fillna(0)

    return df

def create_fraud_labels(df):
    """
    Create fraud labels based on suspicious patterns
    Note: This is a simplified version - in reality, you'd have actual fraud labels
    """
    # Mark transactions as suspicious if they meet certain criteria
    suspicious_conditions = (
        (df['amount_zscore'].abs() > 3) &  # Unusual amount
        (df['trans_count_1d'] > df['trans_count_1d'].mean() + 2*df['trans_count_1d'].std()) &  # High velocity
        (df['balance_change'].abs() > df['balance_change'].abs().mean() + 2*df['balance_change'].abs().std())  # Unusual balance change
    )

    return suspicious_conditions.astype(int)

def prepare_model_data(df):
    """
    Prepare data for model training
    """
    # Select features for the model
    feature_columns = [
        'amount', 'balance', 'amount_zscore', 'trans_count_1d',
        'operation_count', 'hour', 'day_of_week', 'is_weekend'
    ]

    X = df[feature_columns]
    y = create_fraud_labels(df)

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Scale the features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test

def train_fraud_model(X_train, y_train):
    """
    Train the fraud detection model
    """
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=10,
        random_state=42,
        class_weight='balanced'
    )

    model.fit(X_train, y_train)
    return model

def evaluate_model(model, X_test, y_test):
    """
    Evaluate the model performance
    """
    from sklearn.metrics import classification_report, confusion_matrix

    y_pred = model.predict(X_test)

    print("\nConfusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

def main():

    # Load processed data
    df = load_processed_data()
    if df is None:
        return

    # Create features
    df_featured = create_feature_engineering(df)

    # Prepare data for modeling
    X_train, X_test, y_train, y_test = prepare_model_data(df_featured)

    # Train model
    model = train_fraud_model(X_train, y_train)

    # Evaluate model
    evaluate_model(model, X_test, y_test)

if __name__ == "__main__":
    main()